# ===================================================================
# All-Included Deep Research - Backend Configuration
# ===================================================================

# -------------------------------------------------------------------
# API Settings
# -------------------------------------------------------------------
API_HOST=0.0.0.0
API_PORT=8000
DEBUG=false
LOG_LEVEL=INFO

# -------------------------------------------------------------------
# Database Settings (PostgreSQL + pgvector)
# -------------------------------------------------------------------
POSTGRES_HOST=localhost
POSTGRES_PORT=5432
POSTGRES_DB=deep_research
POSTGRES_USER=postgres
POSTGRES_PASSWORD=your_secure_password_here
DATABASE_POOL_SIZE=10

# -------------------------------------------------------------------
# Memory Settings
# -------------------------------------------------------------------
MEMORY_DIR=/home/asudakov/projects/memory_files
CHUNK_SIZE=800
CHUNK_OVERLAP=200

# -------------------------------------------------------------------
# Embedding Provider
# Choose: openai, ollama, cohere, huggingface, mock
# -------------------------------------------------------------------
EMBEDDING_PROVIDER=openai
EMBEDDING_DIMENSION=1536

# OpenAI Embeddings
OPENAI_API_KEY=sk-your-openai-api-key-here
OPENAI_EMBEDDING_MODEL=text-embedding-3-small

# Ollama Embeddings (local, free)
OLLAMA_BASE_URL=http://localhost:11434
OLLAMA_EMBEDDING_MODEL=nomic-embed-text

# Cohere Embeddings
COHERE_API_KEY=your-cohere-api-key-here
COHERE_EMBEDDING_MODEL=embed-english-v3.0
COHERE_INPUT_TYPE=search_document

# HuggingFace Embeddings
HUGGINGFACE_API_KEY=your-huggingface-api-key-here
HUGGINGFACE_MODEL=sentence-transformers/all-MiniLM-L6-v2
HUGGINGFACE_USE_LOCAL=true

# -------------------------------------------------------------------
# Search Provider
# Choose: tavily, searxng, mock
# -------------------------------------------------------------------
SEARCH_PROVIDER=tavily

# Tavily Search
TAVILY_API_KEY=tvly-your-tavily-api-key-here
TAVILY_MAX_RESULTS=8

# SearXNG Search
SEARXNG_INSTANCE_URL=http://localhost:8080
SEARXNG_API_KEY=
SEARXNG_MAX_RESULTS=8
SEARXNG_LANGUAGE=en
SEARXNG_CATEGORIES=
SEARXNG_ENGINES=
SEARXNG_SAFESEARCH=0

# -------------------------------------------------------------------
# LLM Models (LiteLLM format: provider:model_name)
# Examples: openai:gpt-4o, anthropic:claude-3-5-sonnet-20241022
# -------------------------------------------------------------------
LLM_MODE=live
CHAT_MODEL=openai:gpt-4o-mini
CHAT_MODEL_MAX_TOKENS=2048

SEARCH_SUMMARIZATION_MODEL=openai:gpt-4o-mini
SEARCH_SUMMARIZATION_MODEL_MAX_TOKENS=1024

RESEARCH_MODEL=openai:gpt-4o
RESEARCH_MODEL_MAX_TOKENS=4096

COMPRESSION_MODEL=openai:gpt-4o-mini
COMPRESSION_MODEL_MAX_TOKENS=2048

FINAL_REPORT_MODEL=openai:gpt-4o
FINAL_REPORT_MODEL_MAX_TOKENS=8192

# Anthropic (if using Claude)
ANTHROPIC_API_KEY=your-anthropic-api-key-here

# -------------------------------------------------------------------
# Research Mode Configuration
# -------------------------------------------------------------------
# Speed Mode (fast answers)
SPEED_MAX_ITERATIONS=2
SPEED_MAX_CONCURRENT=1

# Balanced Mode (balanced quality/speed)
BALANCED_MAX_ITERATIONS=6
BALANCED_MAX_CONCURRENT=3

# Quality Mode (deep research)
QUALITY_MAX_ITERATIONS=25
QUALITY_MAX_CONCURRENT=5

# -------------------------------------------------------------------
# Advanced Settings
# -------------------------------------------------------------------
# Search tuning
MEMORY_CONTEXT_LIMIT=6
SOURCES_LIMIT=8
SEARCH_CONTENT_MAX_CHARS=6000
SIMPLE_SEARCH_MAX_RESULTS=5
SIMPLE_SEARCH_SCRAPE_TOP_N=2
DEEP_SEARCH_MAX_RESULTS=10
DEEP_SEARCH_QUERIES=4
DEEP_SEARCH_SCRAPE_TOP_N=5
DEEP_SEARCH_RERANK_TOP_K=8
DEEP_SEARCH_ITERATIONS=2

# Retry settings
MAX_RETRIES=3
MAX_STRUCTURED_OUTPUT_RETRIES=3

# RRF (Reciprocal Rank Fusion) parameter
RRF_K=60

# Embedding batch size
EMBEDDING_BATCH_SIZE=100

# Allow clarification questions (quality mode)
ALLOW_CLARIFICATION=true
