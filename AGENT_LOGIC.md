# Агентная логика всех режимов работы

Этот документ описывает детальную логику работы агентов во всех режимах системы.

## Обзор режимов

Система поддерживает 4 основных режима работы:

1. **Chat** - простой диалог без веб-поиска
2. **Web Search** (search) - быстрый веб-поиск с расширением запросов
3. **Deep Search** (deep_search) - качественный веб-поиск с глубокими итерациями
4. **Deep Research** (deep_research) - полноценная мультиагентная система исследования

---

## 1. Chat Mode (Простой диалог)

### Описание
Режим для обычного диалога с LLM без использования веб-поиска и внешних источников.

### Логика работы

**Входные данные:**
- Запрос пользователя
- История чата (последние N сообщений, настраивается через `CHAT_HISTORY_LIMIT`)

**Процесс:**
1. Форматирование истории чата
2. Вызов LLM с системным промптом
3. Генерация структурированного ответа (`SynthesizedAnswer`)
4. Возврат ответа пользователю

**Используемые компоненты:**
- `ChatSearchService.answer_simple()`
- LLM: `chat_model` (настраивается через `CHAT_MODEL`)
- Максимальные токены: `chat_model_max_tokens` (по умолчанию: 16384)

**Особенности:**
- Нет веб-поиска
- Нет источников
- Нет скрапинга
- Простой LLM-ответ на основе обучения модели
- Поддержка истории диалога для контекста (последние N сообщений, настраивается через `CHAT_HISTORY_LIMIT`)
- Structured output с retry логикой для надежности

**Промпт:**
```
You are a helpful AI assistant. Provide clear, accurate, and helpful responses.
Return JSON with fields reasoning, answer, key_points.
Current date: {current_date}
```

**Структурированный вывод:**
```python
class SynthesizedAnswer:
    reasoning: str  # Рассуждения модели
    answer: str     # Основной ответ
    key_points: list[str]  # Ключевые моменты
```

---

## 2. Web Search Mode (Быстрый веб-поиск)

### Описание
Режим для быстрого веб-поиска с расширением запросов и множественными поисковыми запросами.

### Логика работы

**Входные данные:**
- Запрос пользователя
- История чата (опционально)

**Процесс:**

1. **Переформулировка запроса** (`QueryRewrite`)
   - LLM переформулирует запрос для лучшего поиска
   - Используется `search_summarization_model`

2. **Генерация поисковых запросов** (`SearchQueries`)
   - Генерируется 3 поисковых запроса (настраивается через `deep_search_queries`)
   - Каждый запрос - вариация исходного запроса

3. **Итеративный поиск** (2 итерации, настраивается через `speed_max_iterations`)
   - **Итерация 1:**
     - Параллельный поиск по всем сгенерированным запросам
     - Получение результатов (максимум 8 результатов на запрос, настраивается через `deep_search_max_results`)
     - Дедупликация результатов по URL
     - Фильтрация заблокированных доменов/ключевых слов
     - Семантический реранжинг (топ-6 результатов, настраивается через `deep_search_rerank_top_k`)
     - Генерация follow-up запросов для следующей итерации
   
   - **Итерация 2:**
     - Поиск по follow-up запросам
     - Объединение результатов с предыдущей итерацией
     - Дедупликация и фильтрация
     - Реранжинг

4. **Скрапинг топ-URL** (4 URL, настраивается через `deep_search_scrape_top_n`)
   - Параллельный скрапинг топ-результатов
   - Автоматическая суммаризация контента

5. **Синтез ответа** (`SynthesizedAnswer`)
   - LLM синтезирует ответ на основе скрапленного контента
   - Длина ответа: 400-600 слов
   - Включает цитаты источников

**Используемые компоненты:**
- `ChatSearchService.answer_web()`
- `SearchTuning` с параметрами:
  - `mode="web"`
  - `max_results=8`
  - `queries=3`
  - `iterations=2`
  - `scrape_top_n=4`
  - `rerank_top_k=6`

**Особенности:**
- Быстрый режим (2 итерации)
- Множественные поисковые запросы для лучшего покрытия
- Семантический реранжинг результатов (только для SearXNG, Tavily уже оптимизирован)
- Автоматическая суммаризация скрапленного контента
- Цитаты источников в ответе
- Поддержка истории чата для контекста
- Детальное логирование для отладки

**Поток данных:**
```
User Query → Query Rewrite → Generate 3 Search Queries → 
Iteration 1: Search → Dedupe → Filter → Rerank → Follow-up Queries →
Iteration 2: Search → Merge → Dedupe → Filter → Rerank →
Scrape Top 4 URLs → Summarize → Synthesize Answer → Return
```

---

## 3. Deep Search Mode (Качественный веб-поиск)

### Описание
Режим для глубокого веб-поиска с большим количеством итераций и более широким охватом источников.

### Логика работы

**Входные данные:**
- Запрос пользователя
- История чата (опционально)

**Процесс:**

Аналогичен Web Search Mode, но с увеличенными параметрами:

1. **Переформулировка запроса**
2. **Генерация поисковых запросов** (3 запроса)
3. **Итеративный поиск** (6 итераций, настраивается через `balanced_max_iterations`)
   - Каждая итерация:
     - Параллельный поиск
     - Дедупликация
     - Фильтрация
     - Реранжинг
     - Генерация follow-up запросов
4. **Скрапинг топ-URL** (4 URL)
5. **Синтез ответа** (400-600 слов)

**Используемые компоненты:**
- `ChatSearchService.answer_deep()`
- `SearchTuning` с параметрами:
  - `mode="deep"`
  - `max_results=8`
  - `queries=3`
  - `iterations=6`
  - `scrape_top_n=4`
  - `rerank_top_k=6`

**Отличия от Web Search:**
- Больше итераций (6 вместо 2, настраивается через `balanced_max_iterations`)
- Более глубокое исследование темы
- Больше источников рассматривается
- Более тщательный анализ
- Поддержка истории чата для контекста
- Улучшенная обработка ошибок structured output

**Поток данных:**
```
User Query → Query Rewrite → Generate 3 Search Queries → 
Iteration 1-6: Search → Dedupe → Filter → Rerank → Follow-up Queries →
Scrape Top 4 URLs → Summarize → Synthesize Answer → Return
```

---

## 4. Deep Research Mode (Мультиагентная система)

### Описание
Полноценная мультиагентная система исследования с координацией через супервайзера и параллельной работой исследовательских агентов.

### Архитектура

**Компоненты:**
- **Supervisor Agent** - главный координатор, планирует задачи и управляет исследователями
- **Researcher Agents** (1-5 агентов) - выполняют конкретные исследовательские задачи
- **LangGraph Workflow** - оркестрирует весь процесс

### Логика работы

#### Этап 1: Инициализация и подготовка

1. **Deep Search в начале** (опционально, настраивается через `deep_research_run_deep_search_first`)
   - Выполняется быстрый deep search для получения начального контекста
   - Результаты сохраняются в `deep_search_result`

2. **Уточняющие вопросы** (опционально, настраивается через `deep_research_enable_clarifying_questions`)
   - Анализ запроса на необходимость уточнений
   - Генерация вопросов пользователю
   - Ожидание ответов пользователя
   - Ответы сохраняются в `clarification_context`

3. **Анализ запроса** (`analyze_query_node`)
   - Классификация запроса
   - Определение сложности
   - Планирование стратегии исследования

4. **Планирование исследования** (`plan_research_enhanced_node`)
   - Создание плана исследования
   - Определение ключевых аспектов темы
   - Генерация начальных задач

#### Этап 2: Создание агентов

5. **Создание характеристик агентов** (`create_agent_characteristics_enhanced_node`)
   - Определение количества агентов (настраивается через `deep_research_num_agents`, по умолчанию: 4)
   - Создание уникальных характеристик для каждого агента:
     - Специализация (например, "Technical Expert", "Historical Analyst")
     - Стиль работы
     - Предпочтения в источниках

6. **Инициализация агентной памяти**
   - Создание сессионной папки для исследования
   - Структура папки:
     ```
     agent_sessions/{session_id}/
     ├── main.md              # Главный документ исследования (ключевые инсайты)
     ├── draft_report.md      # Черновик финального отчета
     ├── supervisor.md        # Личные заметки супервайзера
     ├── agents/
     │   ├── agent_1.md      # Файл агента 1 (todos, заметки)
     │   ├── agent_2.md      # Файл агента 2
     │   └── ...
     └── items/               # Заметки агентов с источниками
         ├── item_1.md
         └── ...
     ```

#### Этап 3: Выполнение исследования

7. **Параллельное выполнение агентов** (`execute_agents_enhanced_node`)

   **Логика работы агентов:**
   
   - Каждый агент работает в **ReAct-стиле** (Reasoning + Acting)
   - Агенты работают **параллельно**, каждый над своей задачей
   - Один агент = одна задача за раз (enforced в коде)
   - Максимум шагов на задачу: 5 (настраивается через `deep_research_agent_max_steps`, по умолчанию: 5, было 8)
   
   **Инструменты агентов:**
   - `web_search(query: str)` - веб-поиск
     - Принимает естественный запрос (как в браузере)
     - Возвращает результаты с `title`, `url`, `snippet`
   - `scrape_url(urls: list[str])` - скрапинг URL
     - Принимает список URL
     - Возвращает скрапленный и суммаризованный контент
   - `done()` - сигнал завершения задачи
   
   **Процесс работы агента:**
   ```
   1. Агент получает задачу (todo) от супервайзера
   2. Агент анализирует задачу и планирует подход
   3. Агент выполняет поиск/скрапинг
   4. Агент оценивает релевантность результатов
   5. Если результаты нерелевантны - переформулирует запрос (максимум 5 попыток)
   6. Агент создает заметку с находками (только важная информация, не метаданные)
   7. Агент сохраняет заметку в items/ и в свой файл agents/{agent_id}.md
   8. Агент обновляет статус todo на "done"
   9. Агент сигнализирует супервайзеру через SupervisorQueue
   ```
   
   **Память агента:**
   - Агент видит последние 10 важных заметок из своего файла (ограничено для контекста)
   - Агент видит ключевые инсайты из `main.md`
   - Агент видит контекст: исходный запрос, deep search результат, ответы на уточняющие вопросы
   - **ВАЖНО**: Агенты НЕ видят историю чата - только исходный запрос и clarification answers
   
   **Рефлексия агента:**
   - Каждые 3 шага агент рефлексирует
   - Может перепланировать подход, если текущий не работает
   - Может запросить помощь у супервайзера

8. **Координация через SupervisorQueue**

   **Логика очереди:**
   - Когда агент завершает задачу, он добавляется в очередь
   - Супервайзер обрабатывает очередь последовательно
   - После обработки агент получает новую задачу или завершает работу
   
   **Максимум вызовов супервайзера:** 6 (настраивается через `deep_research_max_supervisor_calls`, по умолчанию: 6, было 10)
   - После достижения лимита агенты продолжают работу без вызова супервайзера
   - Агенты завершают все свои задачи
   - Результаты собираются и передаются в черновик отчета

9. **Супервайзер координирует** (`supervisor_review_enhanced_node`)

   **Роль супервайзера:**
   - Просматривает находки агентов
   - Идентифицирует пробелы в исследовании
   - Создает новые задачи для агентов
   - Обеспечивает разнообразие покрытия темы
   - Управляет документами исследования
   
   **Инструменты супервайзера:**
   - `read_supervisor_file()` - читает свои личные заметки
   - `write_supervisor_note()` - пишет заметки в свой файл
   - `read_main_document()` - читает главный документ (только ключевые инсайты)
   - `write_main_document()` - добавляет ключевые инсайты в главный документ
   - `read_draft_report()` - читает черновик отчета
   - `write_draft_report()` - пишет/дополняет черновик отчета
   - `review_agent_progress()` - проверяет прогресс конкретного агента
   - `create_agent_todo()` - создает новую задачу для агента
   - `make_final_decision()` - принимает решение: продолжить/перепланировать/завершить
   
   **Процесс работы супервайзера:**
   ```
   1. Супервайзер получает уведомление о завершении задачи агента
   2. Супервайзер читает находки агента
   3. Супервайзер анализирует находки на глубину и релевантность
   4. Супервайзер пишет заметки в supervisor.md
   5. Супервайзер синтезирует находки в draft_report.md
   6. Супервайзер добавляет ключевые инсайты в main.md
   7. Супервайзер проверяет покрытие темы:
      - Если есть пробелы - создает новые задачи
      - Если находки поверхностные - создает задачи для углубления
      - Если агенты дублируют работу - перенаправляет на разные аспекты
   8. Супервайзер принимает решение:
      - "continue" - продолжить исследование (есть новые задачи)
      - "replan" - перепланировать (направление исследования неверное)
      - "finish" - завершить (исследование достаточно полное)
   ```
   
   **Максимум итераций супервайзера:** 10 (настраивается через `deep_research_supervisor_max_iterations`, по умолчанию: 10, было 15)
   - Если супервайзер не вызывает инструменты 2 раза подряд - принудительное завершение
   - Если достигнут лимит итераций - принудительное завершение
   
   **Критический контекст для супервайзера:**
   - Исходный запрос пользователя
   - Результат начального deep search
   - Ответы пользователя на уточняющие вопросы
   - Все находки агентов (последние 15 полезных находок)
   - **ВАЖНО**: Супервайзер НЕ видит историю чата - только исходный запрос и clarification answers

#### Этап 4: Завершение и генерация отчета

10. **Сжатие находок** (`compress_findings_node`)
    - Объединение всех находок агентов
    - Дедупликация
    - Фильтрация метаданных и мусора
    - Сохранение только важной информации

11. **Генерация финального отчета** (`generate_final_report_enhanced_node`)
    
    **Источники для отчета:**
    - `draft_report.md` (приоритет) - черновик, созданный супервайзером
    - `main.md` (fallback) - главный документ с ключевыми инсайтами
    - `all_findings` (fallback) - все находки агентов
    
    **Процесс:**
    1. Чтение `draft_report.md`
    2. Если черновик слишком короткий (< 1000 символов) или отсутствует - создание из всех находок (без обрезки)
    3. Генерация структурированного отчета через LLM:
       - Executive Summary (200-400 слов)
       - Sections (минимум 3 секции, каждая 300-800 слов)
       - Conclusion (200-400 слов)
    4. Валидация длины отчета (минимум 1500 символов)
    5. Форматирование в Markdown с цитатами источников
    6. Генерация PDF с правильной UTF-8 кодировкой
    7. Кнопка скачать PDF появляется только после завершения deep research
    
    **Структура отчета:**
    ```python
    class FinalReport:
        executive_summary: str  # 200-400 слов
        sections: list[ReportSection]  # Минимум 3 секции
        conclusion: str  # 200-400 слов
        sources: list[str]  # Список источников
    
    class ReportSection:
        title: str
        content: str  # 300-800 слов, markdown
    ```

12. **Сохранение и возврат**
    - Отчет сохраняется в сессионную папку
    - Отчет стримится на фронтенд через SSE
    - Сессионная папка сохраняется после успешного завершения
    - Очистка происходит только при ошибке или отмене

### Параметры Deep Research

**Настройки (в `backend/.env`):**
```bash
# Количество агентов
DEEP_RESEARCH_NUM_AGENTS=4

# Максимум вызовов супервайзера
DEEP_RESEARCH_MAX_SUPERVISOR_CALLS=6

# Максимум шагов на задачу для агента
DEEP_RESEARCH_AGENT_MAX_STEPS=5

# Максимум итераций ReAct для супервайзера
DEEP_RESEARCH_SUPERVISOR_MAX_ITERATIONS=10

# Максимум итераций цикла агентов
DEEP_RESEARCH_DEFAULT_MAX_ITERATIONS=15  # По умолчанию: 15 (было 25)

# Выполнять deep search в начале
DEEP_RESEARCH_RUN_DEEP_SEARCH_FIRST=true

# Задавать уточняющие вопросы
DEEP_RESEARCH_ENABLE_CLARIFYING_QUESTIONS=true
```

### Поток данных Deep Research

```
User Query → Deep Search (optional) → Clarifying Questions (optional) →
Analyze Query → Plan Research → Create Agent Characteristics →
Execute Agents (parallel) → Supervisor Reviews → 
[Continue/Replan/Finish] →
Compress Findings → Generate Final Report → Return
```

### Особенности Deep Research

- **Параллельная работа агентов** - несколько агентов работают одновременно
- **Координация через очередь** - супервайзер обрабатывает завершенные задачи последовательно
- **Диверсификация задач** - супервайзер обеспечивает покрытие разных аспектов темы
- **Глубокая рефлексия** - агенты и супервайзер рефлексируют и перепланируют
- **Управление памятью** - структурированное хранение заметок и документов
- **Гарантированный отчет** - даже при достижении лимитов создается финальный отчет
- **Языковая поддержка** - агенты и супервайзер работают на языке пользователя

---

## Сравнительная таблица режимов

| Параметр | Chat | Web Search | Deep Search | Deep Research |
|----------|------|------------|-------------|---------------|
| Веб-поиск | ❌ | ✅ | ✅ | ✅ |
| Итерации поиска | 0 | 2 | 6 | Динамически |
| Агенты | 0 | 0 | 0 | 1-5 |
| Скрапинг | ❌ | ✅ (4 URL) | ✅ (4 URL) | ✅ (динамически) |
| Реранжинг | ❌ | ✅ | ✅ | ❌ |
| Память агентов | ❌ | ❌ | ❌ | ✅ |
| Уточняющие вопросы | ❌ | ❌ | ❌ | ✅ |
| Длина ответа | Средняя | 400-600 слов | 800-1200 слов | 2000-5000+ слов |
| Время выполнения | < 5 сек | 10-30 сек | 30-60 сек | 2-10 минут |
| Источники | 0 | 4-8 | 8-16 | 20-50+ |
| История чата | ✅ (последние N) | ✅ (последние N) | ✅ (последние N) | ❌ (только исходный запрос + clarification) |
| PDF экспорт | ❌ | ❌ | ❌ | ✅ (после завершения) |

---

## Дополнительные детали

### Языковая поддержка

Все режимы автоматически определяют язык пользователя (через `langdetect`) и:
- Генерируют ответы на языке пользователя
- Используют язык в промптах для агентов
- Форматируют вывод на языке пользователя

### Streaming (SSE и Socket.IO)

Все режимы поддерживают streaming для:
- Реального времени обновлений прогресса (статусы, источники, находки)
- Постепенной передачи ответа (chunks)
- Уведомлений о статусе (инициализация, этапы, завершение)
- Отображения задач агентов в реальном времени (todos, notes)
- Socket.IO для двусторонней коммуникации
- PDF экспорт результатов (только для deep research после завершения)

### Обработка ошибок

- Автоматические повторы при сбоях (настраивается через `max_structured_output_retries`)
- Fallback механизмы для всех structured output вызовов
- Graceful degradation при ошибках LLM
- Детальное логирование всех ошибок с полным контекстом
- Улучшенная обработка None/undefined ответов от LLM
- Защита от ошибок undefined.length на фронтенде

### Производительность

- Параллельная обработка где возможно
- Кэширование результатов
- Оптимизация запросов к LLM
- Эффективное управление памятью

