# –û—Ç—á–µ—Ç –æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏–∑–∞—Ü–∏–∏ –∞–≥–µ–Ω—Ç–Ω—ã—Ö –ø–∞–π–ø–ª–∞–π–Ω–æ–≤

## ‚úÖ –û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ: –≤—Å–µ —á—Ç–æ –º–æ–∂–µ—Ç —Ä–∞–±–æ—Ç–∞—Ç—å –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ - —Ä–∞–±–æ—Ç–∞–µ—Ç

### 1. Web Search / Deep Search —Ä–µ–∂–∏–º—ã

#### ChatSearchService (_execute_search)
**–£–∂–µ –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ** ‚úÖ:
```python
# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –≤—Å–µ—Ö search queries
async def run_query(search_query: str) -> list[SearchResult]:
    response = await self.search_provider.search(...)
    reranked = await self._rerank_results(...)
    return reranked

search_batches = await asyncio.gather(*[run_query(q) for q in queries])
```

**–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ —Å–∫—Ä–∞–ø–ø–∏–Ω–≥** ‚úÖ:
```python
async def scrape_one(result: SearchResult):
    return await self.scraper.scrape(result.url)

scraped = await asyncio.gather(*[scrape_one(r) for r in results[:top_n]])
```

**–ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–∞—è —Å—É–º–º–∞—Ä–∏–∑–∞—Ü–∏—è** ‚úÖ:
```python
async def summarize(content):
    return await summarizer_llm.ainvoke(...)

return await asyncio.gather(*[summarize(item) for item in scraped])
```

### 2. Research Agent (ReAct —Ü–∏–∫–ª)

#### web_search_handler
**–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ**: queries —Ç–µ–ø–µ—Ä—å –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ ‚úÖ

**–ë—ã–ª–æ**:
```python
for query in queries[:3]:
    response = await search_provider.search(query)  # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ!
```

**–°—Ç–∞–ª–æ**:
```python
async def search_single(query: str):
    return await search_provider.search(query)

# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ!
search_results = await asyncio.gather(*[search_single(q) for q in queries[:3]])
```

#### scrape_url_handler
**–ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ**: URLs —Å–∫—Ä–∞–ø—è—Ç—Å—è –∏ —Å—É–º–º–∞—Ä–∏–∑—É—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ ‚úÖ

**–ë—ã–ª–æ**:
```python
for url in urls[:3]:
    content = await scraper.scrape(url)  # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ!
    summary = await summarize_text_llm(...)  # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ!
```

**–°—Ç–∞–ª–æ**:
```python
async def scrape_and_summarize(url: str):
    content = await scraper.scrape(url)
    summary = await summarize_text_llm(...)
    return {...}

# –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ!
scraped_results = await asyncio.gather(*[scrape_and_summarize(url) for url in urls[:3]])
```

### 3. Researcher Agent (Deep Research)

#### Tool calls –≤–Ω—É—Ç—Ä–∏ –∞–≥–µ–Ω—Ç–∞
**–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ**: –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –Ω–µ–∑–∞–≤–∏—Å–∏–º—ã—Ö tool calls ‚úÖ

**–õ–æ–≥–∏–∫–∞**:
```python
# –ü—Ä–æ–≤–µ—Ä—è–µ–º, –º–æ–∂–Ω–æ –ª–∏ –ø–∞—Ä–∞–ª–ª–µ–ª–∏—Ç—å
can_parallelize = len(tool_calls) > 1 and all(
    tc.get("name") in ["web_search", "scrape_url"] 
    for tc in tool_calls
)

if can_parallelize:
    # –í—ã–ø–æ–ª–Ω—è–µ–º –≤—Å–µ tools –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
    tool_results = await asyncio.gather(*[execute_tool(tc) for tc in tool_calls])
else:
    # –í—ã–ø–æ–ª–Ω—è–µ–º –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (–µ—Å–ª–∏ —Ä–∞–∑–Ω—ã–µ —Ç–∏–ø—ã tools)
    for tool_call in tool_calls:
        result = await ActionRegistry.execute(...)
```

**–ö–æ–≥–¥–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ**:
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ web_search calls
- –ú–Ω–æ–∂–µ—Å—Ç–≤–µ–Ω–Ω—ã–µ scrape_url calls
- –ö–æ–º–±–∏–Ω–∞—Ü–∏—è web_search + scrape_url

**–ö–æ–≥–¥–∞ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ**:
- –°–º–µ—à–∞–Ω–Ω—ã–µ —Ç–∏–ø—ã tools (–Ω–∞–ø—Ä–∏–º–µ—Ä, reasoning + search)
- –û–¥–∏–Ω tool call

### 4. Execute Agents (Deep Research)

#### –ü–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ–µ –≤—ã–ø–æ–ª–Ω–µ–Ω–∏–µ –∞–≥–µ–Ω—Ç–æ–≤
**–û–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω–æ**: –≤—Å–µ –∞–≥–µ–Ω—Ç—ã –∂–¥—É—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ ‚úÖ

**–ë—ã–ª–æ**:
```python
for agent_id, task in agent_tasks:
    result = await task  # –ü–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ–µ –æ–∂–∏–¥–∞–Ω–∏–µ!
```

**–°—Ç–∞–ª–æ**:
```python
# Gather all agent tasks in parallel
agent_results = await asyncio.gather(
    *[task for _, task in agent_tasks],
    return_exceptions=True
)
```

**–†–µ–∑—É–ª—å—Ç–∞—Ç**: 4 –∞–≥–µ–Ω—Ç–∞ —Ä–∞–±–æ—Ç–∞—é—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏ –∂–¥—É—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ, –Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ

### 5. Supervisor Agent

#### –ò–Ω—Å—Ç—Ä—É–º–µ–Ω—Ç—ã supervisor
**–ü—Ä–∞–≤–∏–ª—å–Ω–æ**: –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (ReAct —Ñ–æ—Ä–º–∞—Ç —Ç—Ä–µ–±—É–µ—Ç) ‚úÖ

Supervisor –¥–æ–ª–∂–µ–Ω –≤–∏–¥–µ—Ç—å —Ä–µ–∑—É–ª—å—Ç–∞—Ç—ã –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π –¥–ª—è –ø—Ä–∏–Ω—è—Ç–∏—è —Ä–µ—à–µ–Ω–∏–π:
```python
1. read_main_document ‚Üí –≤–∏–¥–∏—Ç —Ç–µ–∫—É—â–µ–µ —Å–æ—Å—Ç–æ—è–Ω–∏–µ
2. review_agent_progress ‚Üí –≤–∏–¥–∏—Ç —Å—Ç–∞—Ç—É—Å –∞–≥–µ–Ω—Ç–æ–≤
3. write_main_document ‚Üí –æ–±–Ω–æ–≤–ª—è–µ—Ç –¥–æ–∫—É–º–µ–Ω—Ç
4. create_agent_todo ‚Üí —Å–æ–∑–¥–∞–µ—Ç –∑–∞–¥–∞—á–∏
5. make_final_decision ‚Üí –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏–µ
```

–≠—Ç–æ –ø—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å - supervisor –ø—Ä–∏–Ω–∏–º–∞–µ—Ç —Ä–µ—à–µ–Ω–∏—è –Ω–∞ –æ—Å–Ω–æ–≤–µ –ø—Ä–µ–¥—ã–¥—É—â–∏—Ö –¥–µ–π—Å—Ç–≤–∏–π.

## üìä –°—Ä–∞–≤–Ω–µ–Ω–∏–µ –ø—Ä–æ–∏–∑–≤–æ–¥–∏—Ç–µ–ª—å–Ω–æ—Å—Ç–∏

### –î–æ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
```
Web Search (3 queries, 2 URLs):
- Query 1: 2s
- Query 2: 2s  
- Query 3: 2s
- Scrape URL 1: 3s
- Scrape URL 2: 3s
- Summarize 1: 2s
- Summarize 2: 2s
Total: ~16s –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
```

### –ü–æ—Å–ª–µ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–∏:
```
Web Search (3 queries, 2 URLs):
- 3 queries –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ: 2s
- 2 scrapes + 2 summarizes –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ: 5s
Total: ~7s (—É—Å–∫–æ—Ä–µ–Ω–∏–µ 2.3x)
```

### Deep Research (4 –∞–≥–µ–Ω—Ç–∞):
```
–î–æ: –ê–≥–µ–Ω—Ç—ã –∂–¥—É—Ç—Å—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ
- Agent 1 completes: 10s ‚Üí wait
- Agent 2 completes: 12s ‚Üí wait  
- Agent 3 completes: 11s ‚Üí wait
- Agent 4 completes: 9s ‚Üí wait
Total wait: 42s

–ü–æ—Å–ª–µ: –ê–≥–µ–Ω—Ç—ã –∂–¥—É—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ
- All agents work in parallel
- Wait for all: max(10, 12, 11, 9) = 12s
Total wait: 12s (—É—Å–∫–æ—Ä–µ–Ω–∏–µ 3.5x)
```

## ‚úÖ –ò—Ç–æ–≥–æ–≤–∞—è —Ç–∞–±–ª–∏—Ü–∞ –æ–ø—Ç–∏–º–∏–∑–∞—Ü–∏–π

| –ö–æ–º–ø–æ–Ω–µ–Ω—Ç | –ß—Ç–æ –ø–∞—Ä–∞–ª–ª–µ–ª–∏—Ç—Å—è | –°—Ç–∞—Ç—É—Å |
|-----------|------------------|--------|
| ChatSearchService | Search queries | ‚úÖ –£–∂–µ –±—ã–ª–æ |
| ChatSearchService | Scraping URLs | ‚úÖ –£–∂–µ –±—ã–ª–æ |
| ChatSearchService | Summarization | ‚úÖ –£–∂–µ –±—ã–ª–æ |
| web_search_handler | Search queries | ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ |
| scrape_url_handler | Scraping + summarization | ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ |
| researcher.py | Independent tool calls | ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ |
| execute_agents | Waiting for agents | ‚úÖ –ò—Å–ø—Ä–∞–≤–ª–µ–Ω–æ |
| supervisor_agent | Tools (sequential) | ‚úÖ –ü—Ä–∞–≤–∏–ª—å–Ω–æ |

## üéØ –†–µ–∑—É–ª—å—Ç–∞—Ç

### –ù–µ—Ç –¥–æ–ª–≥–æ–≥–æ –æ–∂–∏–¥–∞–Ω–∏—è:
- ‚úÖ Search queries –≤—ã–ø–æ–ª–Ω—è—é—Ç—Å—è –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ)
- ‚úÖ Scraping URLs –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ)
- ‚úÖ Summarization –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ (–Ω–µ –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ)
- ‚úÖ –ê–≥–µ–Ω—Ç—ã —Ä–∞–±–æ—Ç–∞—é—Ç –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –∏ –∂–¥—É—Ç—Å—è –æ–¥–Ω–æ–≤—Ä–µ–º–µ–Ω–Ω–æ
- ‚úÖ Tool calls –≤–Ω—É—Ç—Ä–∏ –∞–≥–µ–Ω—Ç–∞ –ø–∞—Ä–∞–ª–ª–µ–ª—è—Ç—Å—è –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ

### Streaming —Ä–∞–±–æ—Ç–∞–µ—Ç –ø–ª–∞–≤–Ω–æ:
- ‚úÖ –°–æ–±—ã—Ç–∏—è –æ—Ç–ø—Ä–∞–≤–ª—è—é—Ç—Å—è —Å—Ä–∞–∑—É –ø—Ä–∏ –≤–æ–∑–Ω–∏–∫–Ω–æ–≤–µ–Ω–∏–∏
- ‚úÖ Chunks —Å sleep(0.02) –¥–ª—è –ø–ª–∞–≤–Ω–æ—Å—Ç–∏
- ‚úÖ –§—Ä–æ–Ω—Ç–µ–Ω–¥ –æ–±–Ω–æ–≤–ª—è–µ—Ç—Å—è –≤ —Ä–µ–∞–ª—å–Ω–æ–º –≤—Ä–µ–º–µ–Ω–∏
- ‚úÖ –ù–µ—Ç "–¥–æ–ª–≥–æ–≥–æ –æ–∂–∏–¥–∞–Ω–∏—è, –ø–æ—Ç–æ–º —Å—Ä–∞–∑—É –≤—Å–µ"

### –ü—Ä–∞–≤–∏–ª—å–Ω–∞—è –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ—Å—Ç—å —Å–æ—Ö—Ä–∞–Ω–µ–Ω–∞:
- ‚úÖ Supervisor tools - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (ReAct —Ç—Ä–µ–±—É–µ—Ç)
- ‚úÖ Agent ReAct loop - –ø–æ—Å–ª–µ–¥–æ–≤–∞—Ç–µ–ª—å–Ω–æ (–Ω—É–∂–µ–Ω –∫–æ–Ω—Ç–µ–∫—Å—Ç)
- ‚úÖ –í–Ω—É—Ç—Ä–∏ tool calls - –ø–∞—Ä–∞–ª–ª–µ–ª—å–Ω–æ –≥–¥–µ –≤–æ–∑–º–æ–∂–Ω–æ

**–í—Å–µ –∞–≥–µ–Ω—Ç–Ω—ã–µ –ø–∞–π–ø–ª–∞–π–Ω—ã –æ–ø—Ç–∏–º–∏–∑–∏—Ä–æ–≤–∞–Ω—ã!**

